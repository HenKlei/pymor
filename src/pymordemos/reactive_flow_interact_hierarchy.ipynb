{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0afb673c-7199-42ce-82ab-1e2fbf34ff00",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "from IPython import get_ipython\n",
        "\n",
        "import pymor.tools.random\n",
        "\n",
        "ip = get_ipython()\n",
        "if ip is not None:\n",
        "#    ip.run_line_magic('matplotlib', 'inline')\n",
        "    ip.run_line_magic('matplotlib', 'ipympl')\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='torch')\n",
        "\n",
        "pymor.tools.random._default_random_state = None\n",
        "\n",
        "mpl.rcParams['figure.facecolor'] = (1.0, 1.0, 1.0, 0.0)\n",
        "\n",
        "from pymor.core.logger import getLogger, set_log_levels\n",
        "\n",
        "set_log_levels({ # disable logging for some components\n",
        "    'main': 'DEBUG',\n",
        "    'pymor': 'WARN',\n",
        "    'pymor.models': 'WARN',\n",
        "    'pymor.discretizers.builtin': 'WARN',\n",
        "    'pymor.discretizers.dunegdt': 'DEBUG',\n",
        "    'pymor.analyticalproblems.functions.BitmapFunction': 'ERROR',\n",
        "    'models.ann.ANNStateReductor': 'INFO',\n",
        "    'models.vkoga.VkogaStateModel': 'INFO',\n",
        "    'models.vkoga.VkogaStateReductor': 'DEBUG',\n",
        "    'models.adaptive': 'DEBUG',\n",
        "    'algorithms.optimization': 'DEBUG'})\n",
        "\n",
        "logger = getLogger('main.main')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc319ea-5a2f-47f1-9e2e-0f1f9010923e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# FOM\n",
        "num_refines = 0\n",
        "num_timesteps = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d2c212-ea16-4329-9bb1-57a79ece32a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymor.basic import *\n",
        "\n",
        "\n",
        "def setup_problem_and_discretize(num_refines, nt):\n",
        "    from spe10channel import discretize, make_problem\n",
        "\n",
        "    grid, boundary_info, problem, parameter_space, mu_bar = make_problem(\n",
        "        regime='diffusion dominated', num_global_refines=num_refines)\n",
        "\n",
        "    fom, fom_data, coercivity_estimator = discretize(\n",
        "        grid, boundary_info, problem, mu_bar, nt=nt)\n",
        "\n",
        "    return parameter_space, fom, fom_data, coercivity_estimator\n",
        "\n",
        "\n",
        "spatial_product = lambda m: m.energy_0_product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95bd5b1-50ae-4ba6-ab9a-6f814df7b082",
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.info('creating FOM:')\n",
        "tic = time.perf_counter()\n",
        "\n",
        "parameter_space, fom, fom_data, coercivity_estimator = setup_problem_and_discretize(\n",
        "    num_refines, num_timesteps)\n",
        "\n",
        "fom_offline_time = time.perf_counter() - tic\n",
        "logger.info(f'  discretizing took {fom_offline_time}s')\n",
        "logger.info(f'  grid has {fom_data[\"grid\"].size(0)} elements,'\n",
        "            f'FOM has {fom.solution_space.dim} DoFs, '\n",
        "            f'uses {fom.time_stepper.nt} time steps')\n",
        "\n",
        "logger.info(f'  input parameter space is {parameter_space.parameters.dim}-dimensional:')\n",
        "logger.info(f'    {parameter_space}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7c3eca-1703-4db3-9568-e6a8f008c780",
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.info('computing dual norm of output functional:')\n",
        "\n",
        "assert not fom.output_functional.parametric\n",
        "riesz_representative = spatial_product(fom).apply_inverse(fom.output_functional.as_vector())\n",
        "dual_norm_output = np.sqrt(spatial_product(fom).apply2(riesz_representative, riesz_representative)[0][0])\n",
        "del riesz_representative\n",
        "\n",
        "logger.info(f'  {dual_norm_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bdc9b3e-0288-4e15-976c-b9e90e72a17f",
      "metadata": {},
      "outputs": [],
      "source": [
        "mu_ref = parameter_space.sample_uniformly(1)[0]\n",
        "\n",
        "logger.info(f'computing f_h(mu={mu_ref}) ...')\n",
        "\n",
        "tic = timer()\n",
        "f_mu_ref = fom.output(mu=mu_ref, incremental=True)  # no need to keep the state trajectory in memory\n",
        "fom_online_output_time = timer() - tic\n",
        "\n",
        "logger.info(f'average FOM output (solve + apply functional) time: {fom_online_output_time}s')\n",
        "\n",
        "logger.info('computing ||f_mu_ref||_{L^2(0, T)}:')\n",
        "initial_abs_output_tol = fom.output_l2_norm(f_mu_ref)\n",
        "logger.info(f'  {initial_abs_output_tol}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5919a0-62ce-4337-a86a-890236f35118",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymor.models.hierarchy import AdaptiveModelHierarchy\n",
        "from pymor.reductors.neural_network import NeuralNetworkReductor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c62c3fbe-c684-43c2-a8f6-1c21ed984b27",
      "metadata": {},
      "outputs": [],
      "source": [
        "rb_reductor = CoerciveRBReductor(\n",
        "    fom,\n",
        "    product=fom.h1_0_semi_product,\n",
        "    coercivity_estimator=ExpressionParameterFunctional('min(diffusion)', fom.parameters)\n",
        ")\n",
        "#ParabolicRBReductor, product=spatial_product(fom), coercivity_estimator=coercivity_estimator\n",
        "\n",
        "def reduction_rb(training_data, len_previous_training_data, models, reductors):\n",
        "    U = fom.solution_space.empty(reserve=len(training_data))\n",
        "    for _, u in training_data[len_previous_training_data:]:\n",
        "        U.append(u)\n",
        "    RB, _ = pod(U, product=fom.h1_0_semi_product)\n",
        "    reductors[0].extend_basis(RB)\n",
        "    return reductors[0].reduce()\n",
        "\n",
        "def post_reduction_rb(training_data, models, reductors):\n",
        "    return []\n",
        "\n",
        "tolerance = 5e-3\n",
        "\n",
        "# Settings for the two-stage hierarchy\n",
        "models = [rb_reductor.reduce(), fom]\n",
        "model_names = ['RB-ROM', 'FOM']\n",
        "reductors = [rb_reductor]\n",
        "reduction_methods = [reduction_rb]\n",
        "post_reduction_methods = [post_reduction_rb]\n",
        "training_frequencies = [1]\n",
        "\n",
        "two_stage_hierarchy = AdaptiveModelHierarchy(models, reductors, reduction_methods, post_reduction_methods,\n",
        "                                             training_frequencies, tolerance, visualizer=fom.visualizer,\n",
        "                                             name='Two-stage model hierarchy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daef41fe-6452-4596-8093-2a0d4bb2814b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def Linf_misfit(m, x, f_ref=None, print_status=False):\n",
        "    if print_status:\n",
        "        print('.', end='', flush=True)\n",
        "    mu = m.parameters.parse(x)\n",
        "    f_x = m.output(mu, incremental=True)\n",
        "    if f_ref is None:\n",
        "        f_ref = m.output(mu=mu_ref, incremental=True)\n",
        "    return np.max(np.abs((f_ref - f_x).to_numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a16970-50e7-4019-931d-12add348102b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymor.models.interact import interact_model_hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c9197b-dab9-497b-aa26-6836f6bc1691",
      "metadata": {},
      "outputs": [],
      "source": [
        "interact_model_hierarchy(two_stage_hierarchy, parameter_space, model_names,\n",
        "                         partial(Linf_misfit, f_ref=f_mu_ref))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc82200a-f4df-46c7-a28e-052afa3443a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_reductor = NeuralNetworkReductor(fom=fom, training_set=None, validation_set=None,\n",
        "                                    ann_mse=None, pod_params={'product': fom.h1_0_semi_product},\n",
        "                                    scale_inputs=False, scale_outputs=False)\n",
        "\n",
        "def reduction_ml(training_data, len_previous_training_data, models, reductors):\n",
        "    rb_rom = models[1]\n",
        "    rb_reductor = reductors[1]\n",
        "    ml_reductor = reductors[0]\n",
        "    error_estimator = rb_rom.error_estimator\n",
        "    ml_reductor.reduced_basis = rb_reductor.bases['RB']\n",
        "    red_dim = len(ml_reductor.reduced_basis)\n",
        "    training_data = [(mu, np.pad(dat.to_numpy()[0], (0, red_dim - len(dat.to_numpy()[0])),\n",
        "                                 mode='constant', constant_values=0.))\n",
        "                     for (mu, dat) in training_data]\n",
        "    ml_reductor.training_data = training_data\n",
        "    ml_rom = ml_reductor.reduce(restarts=2, log_loss_frequency=10, recompute_training_data=False,\n",
        "                                recompute_validation_data=True)\n",
        "    return ml_rom.with_(error_estimator=error_estimator)\n",
        "\n",
        "def post_reduction_ml(training_data, models, reductors):\n",
        "    return []\n",
        "\n",
        "def post_reduction_rb(training_data, models, reductors):\n",
        "    return [models[0]]\n",
        "    #return [reduction_ml(training_data[1], None, models, reductors)]\n",
        "\n",
        "models = [None, rb_reductor.reduce(), fom]\n",
        "model_names = ['ML-ROM', 'RB-ROM', 'FOM']\n",
        "reductors = [ml_reductor, rb_reductor]\n",
        "reduction_methods = [reduction_ml, reduction_rb]\n",
        "post_reduction_methods = [post_reduction_ml, post_reduction_rb]\n",
        "training_frequencies = [20, 1]\n",
        "\n",
        "three_stage_hierarchy = AdaptiveModelHierarchy(models, reductors, reduction_methods, post_reduction_methods,\n",
        "                                               training_frequencies, tolerance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5589c177-0026-41c2-b60b-207c40b0ab3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "interact_model_hierarchy(three_stage_hierarchy, parameter_space, model_names,\n",
        "                         visualizer=fom.visualize)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
