{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb673c-7199-42ce-82ab-1e2fbf34ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image\n",
    "\n",
    "import pymor.tools.random\n",
    "\n",
    "ip = get_ipython()\n",
    "if ip is not None:\n",
    "#    ip.run_line_magic('matplotlib', 'inline')\n",
    "    ip.run_line_magic('matplotlib', 'ipympl')\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='torch')\n",
    "\n",
    "pymor.tools.random._default_random_state = None\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = (1.0, 1.0, 1.0, 0.0)\n",
    "#mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "from pymor.core.logger import getLogger, set_log_levels\n",
    "\n",
    "set_log_levels({ # disable logging for some components\n",
    "    'main': 'DEBUG',\n",
    "    'pymor': 'WARN',\n",
    "    'pymor.models': 'WARN',\n",
    "    'pymor.discretizers.builtin': 'WARN',\n",
    "    'pymor.discretizers.dunegdt': 'DEBUG',\n",
    "    'pymor.analyticalproblems.functions.BitmapFunction': 'ERROR',\n",
    "    'models.ann.ANNStateReductor': 'INFO',\n",
    "    'models.vkoga.VkogaStateModel': 'INFO',\n",
    "    'models.vkoga.VkogaStateReductor': 'DEBUG',\n",
    "    'models.adaptive': 'DEBUG',\n",
    "    'algorithms.optimization': 'DEBUG'})\n",
    "\n",
    "logger = getLogger('main.main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc319ea-5a2f-47f1-9e2e-0f1f9010923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOM\n",
    "num_refines = 2\n",
    "num_timesteps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2c212-ea16-4329-9bb1-57a79ece32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.basic import *\n",
    "\n",
    "\n",
    "def setup_problem_and_discretize(num_refines, nt):\n",
    "    from spe10channel import discretize, make_problem\n",
    "\n",
    "    grid, num_grid_elements, boundary_info, problem, parameter_space, mu_bar = make_problem(\n",
    "        regime='diffusion dominated', num_global_refines=num_refines)\n",
    "\n",
    "    fom, fom_data, coercivity_estimator = discretize(\n",
    "        grid, num_grid_elements, boundary_info, problem, mu_bar, nt=nt)\n",
    "\n",
    "    return parameter_space, fom, fom_data, coercivity_estimator\n",
    "\n",
    "\n",
    "spatial_product = lambda m: m.energy_0_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bd5b1-50ae-4ba6-ab9a-6f814df7b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('creating FOM:')\n",
    "tic = time.perf_counter()\n",
    "\n",
    "parameter_space, fom, fom_data, coercivity_estimator = setup_problem_and_discretize(\n",
    "    num_refines, num_timesteps)\n",
    "\n",
    "fom_offline_time = time.perf_counter() - tic\n",
    "logger.info(f'  discretizing took {fom_offline_time}s')\n",
    "logger.info(f'  grid has {fom_data[\"grid\"].size(0)} elements,'\n",
    "            f'FOM has {fom.solution_space.dim} DoFs, '\n",
    "            f'uses {fom.time_stepper.nt} time steps')\n",
    "\n",
    "logger.info(f'  input parameter space is {parameter_space.parameters.dim}-dimensional:')\n",
    "logger.info(f'    {parameter_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c3eca-1703-4db3-9568-e6a8f008c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('computing dual norm of output functional:')\n",
    "\n",
    "assert not fom.output_functional.parametric\n",
    "riesz_representative = spatial_product(fom).apply_inverse(fom.output_functional.as_vector())\n",
    "dual_norm_output = np.sqrt(spatial_product(fom).apply2(riesz_representative, riesz_representative)[0][0])\n",
    "del riesz_representative\n",
    "\n",
    "logger.info(f'  {dual_norm_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5919a0-62ce-4337-a86a-890236f35118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.models.hierarchy import AdaptiveModelHierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c3fbe-c684-43c2-a8f6-1c21ed984b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_reductor = ParabolicRBReductor(fom, product=spatial_product(fom), coercivity_estimator=coercivity_estimator)\n",
    "\n",
    "def reduction_rb(training_data, len_previous_training_data, models, reductors):\n",
    "    U = fom.solution_space.empty(reserve=len(training_data))\n",
    "    for _, u in training_data[len_previous_training_data:]:\n",
    "        U.append(u)\n",
    "    RB, _ = pod(U, product=fom.h1_0_semi_product)\n",
    "    reductors[0].extend_basis(RB)\n",
    "    # TODO: Use HaPOD here!!!\n",
    "    return reductors[0].reduce()\n",
    "\n",
    "def post_reduction_rb(training_data, models, reductors):\n",
    "    return []\n",
    "\n",
    "tolerance = 5e-3\n",
    "\n",
    "# Settings for the two-stage hierarchy\n",
    "models = [rb_reductor.reduce(), fom]\n",
    "model_names = ['RB-ROM', 'FOM']\n",
    "reductors = [rb_reductor]\n",
    "reduction_methods = [reduction_rb]\n",
    "post_reduction_methods = [post_reduction_rb]\n",
    "training_frequencies = [1]\n",
    "\n",
    "two_stage_hierarchy = AdaptiveModelHierarchy(models, reductors, reduction_methods, post_reduction_methods,\n",
    "                                             training_frequencies, tolerance, visualizer=fom.visualizer,\n",
    "                                             name='Two-stage model hierarchy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356fca3a-7b66-4de4-af14-b174a4c2ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_init = fom.parameters.parse([9.5, 9.5])\n",
    "mu_opt = fom.parameters.parse([3.1647, 11.0])\n",
    "\n",
    "def objective_function(output, mu):\n",
    "    return fom.T * np.mean(output) + 1/500 * mu[\"Da\"][0]**2 - 1/10 * (mu[\"Pe\"][0] - 9.)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48990550-0b09-40c7-b714-60671d702dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "num_params = 20\n",
    "uniform_params = parameter_space.sample_uniformly(num_params)\n",
    "res = np.zeros((num_params, num_params))\n",
    "for i, mu in enumerate(uniform_params):\n",
    "    output = fom.output(mu).flatten()\n",
    "    res[(i-(i%num_params))//num_params, i%num_params] = objective_function(output, mu)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close()\n",
    "fig, axs = plt.subplots()\n",
    "mp = axs.imshow(res.T, origin='lower')\n",
    "fig.colorbar(mp, ax=axs)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec8d36-921a-4994-87e0-4499dca778d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "res_alt = res.copy()\n",
    "params_array = np.array([p.to_numpy() for p in uniform_params]).reshape((num_params, num_params, 2))\n",
    "s = 1/500\n",
    "t = 1/10\n",
    "res_alt += s * params_array[..., 0]**2 - t * (params_array[..., 1] - 9.)**2\n",
    "#print(f\"Matrix of output values: {res_alt}\")\n",
    "print(f\"Minimum value: {np.min(res_alt)}\")\n",
    "amin = np.unravel_index(res_alt.argmin(), res_alt.shape)\n",
    "print(f\"Minimum index: {amin}\")\n",
    "print(f\"Minimum parameter: {uniform_params[amin[0]*num_params+amin[1]]}\")\n",
    "plt.close()\n",
    "fig_alt, axs_alt = plt.subplots(1, 2)\n",
    "mp = axs_alt[0].imshow(res.T, origin='lower')\n",
    "fig_alt.colorbar(mp, ax=axs_alt[0])\n",
    "mp_alt = axs_alt[1].imshow(res_alt.T, origin='lower')\n",
    "fig_alt.colorbar(mp_alt, ax=axs_alt[1])\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65457f51-a4cf-45ca-abe8-ebf297ebf84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = plt.figure(frameon=False)\n",
    "fig.set_size_inches(1, 1)\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "ax.imshow(res.T, origin='lower', aspect='auto')\n",
    "fig.savefig('fig_optimization_background_new.png', dpi=100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3f886-56ca-4950-93ab-95031b2da694",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (5.005, 10)\n",
    "cov = [[2, 0], [0, 1]]\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "rv = multivariate_normal(mean, cov)\n",
    "\n",
    "def random_sampling_function():\n",
    "    return rv.rvs()\n",
    "\n",
    "density_function_monte_carlo = rv.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a16970-50e7-4019-931d-12add348102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.models.interact import interact_model_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82200a-f4df-46c7-a28e-052afa3443a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.reductors.ml import MachineLearningInstationaryReductor\n",
    "\n",
    "method = 'gpr'\n",
    "model_parameters = {}\n",
    "\n",
    "ml_reductor = MachineLearningInstationaryReductor(fom=fom, training_set=None, validation_set=None, method=method, model_parameters=model_parameters, product=fom.h1_0_semi_product)\n",
    "\n",
    "def reduction_ml(training_data, len_previous_training_data, models, reductors):\n",
    "    rb_rom = models[1]\n",
    "    rb_reductor = reductors[1]\n",
    "    ml_reductor = reductors[0]\n",
    "    error_estimator = rb_rom.error_estimator\n",
    "    ml_reductor.reduced_basis = rb_reductor.bases['RB']\n",
    "    red_dim = len(ml_reductor.reduced_basis)\n",
    "    training_data = [(mu, np.pad(dat.to_numpy()[0], (0, red_dim - len(dat.to_numpy()[0])),\n",
    "                                 mode='constant', constant_values=0.))\n",
    "                     for (mu, dat) in training_data if np.linalg.norm(dat.to_numpy().flatten()) > 1e-10]\n",
    "    ml_reductor.training_data = training_data\n",
    "    ml_rom = ml_reductor.reduce()\n",
    "    return ml_rom.with_(error_estimator=error_estimator, T=rb_rom.T, time_stepper=rb_rom.time_stepper)\n",
    "\n",
    "def post_reduction_ml(training_data, models, reductors):\n",
    "    return []\n",
    "\n",
    "def post_reduction_rb(training_data, models, reductors):\n",
    "    return [models[0]]\n",
    "    #return [reduction_ml(training_data[1], None, models, reductors)]\n",
    "\n",
    "models = [None, rb_reductor.reduce(), fom]\n",
    "model_names = ['ML-ROM', 'RB-ROM', 'FOM']\n",
    "reductors = [ml_reductor, rb_reductor]\n",
    "reduction_methods = [reduction_ml, reduction_rb]\n",
    "post_reduction_methods = [post_reduction_ml, post_reduction_rb]\n",
    "training_frequencies = [10, 1]\n",
    "\n",
    "three_stage_hierarchy = AdaptiveModelHierarchy(models, reductors, reduction_methods, post_reduction_methods,\n",
    "                                               training_frequencies, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879e70b-2b41-4589-9e2f-cc8283ba2963",
   "metadata": {},
   "source": [
    "# Katalytische Filter\n",
    "\n",
    "Wir betrachten eine parametrisierte lineare Advektions-Diffusions-Reaktions-Gleichung in einem künstlichen Leitungsrohr $\\Omega=[0,5]\\times[0,1]=\\Omega_\\mathrm{w}\\cup\\Omega_\\mathrm{c}$, aufgeteilt in einen Washcoat $\\Omega_\\mathrm{w}=[0,5]\\times[0,h_\\mathrm{w}]$ der Höhe $h_\\mathrm{w}=0.34$ und einen Kanal $\\Omega_\\mathrm{c}=\\Omega\\setminus\\Omega_\\mathrm{w}$ mit Einflussrand $\\Gamma_\\mathrm{in}=\\{x=0\\}\\times[h_\\mathrm{w},1]$ und Ausflussrand $\\Gamma_\\mathrm{out}=\\{x=5\\}\\times[h_\\mathrm{w},1]$. Für jeden Parameter $\\mu=(\\mathrm{Da},\\mathrm{Pe})\\in\\mathcal{P}$ aus der Parametermenge $\\mathcal{P}=[0.01,10]\\times[9,11]$ suchen wir die Lösung $u(\\mu)\\in L^2(0,T;V_g)$ mit $\\partial_tu(\\mu)\\in L^2(0,T;V_0')$ der Gleichung für $T=5$:\n",
    "\n",
    "$$\n",
    "    \\partial_t u(\\mu)-\\nabla\\cdot(\\kappa\\nabla u(\\mu))+\\mathrm{Pe}\\nabla\\cdot(\\vec{v}u(\\mu))+\\mathrm{Da}\\chi_{\\Omega_\\mathrm{w}}u(\\mu)=0\\qquad\\text{in }\\Omega\\times(0,T)\n",
    "$$\n",
    "\n",
    "mit Neumann-Randbedingung $(\\kappa\\nabla u(\\mu))\\cdot n_{\\partial \\Omega}=0$ auf $\\Gamma_\\mathrm{out}$, Dirichlet-Randbedingung $u(\\mu)=g=\\chi_{\\Gamma_\\mathrm{in}}$ auf $\\partial\\Omega\\setminus\\Gamma_\\mathrm{out}$ und Anfangsbedingung $u(t=0;\\mu)=\\chi_{\\Gamma_\\mathrm{in}}$. Das Advektionsfeld ist definiert als $\\vec{v}=(\\chi_{\\Omega_\\mathrm{c}},0)^\\top$ und die Diffusion $\\kappa$ ist gegeben durch $1$ im Kanal $\\Omega_\\mathrm{c}$ beziehungsweise durch die erste Komponente des Permeabilitätsfeldes des Spe10 Modells im Washcoat $\\Omega_\\mathrm{w}$.\n",
    "\n",
    "Das Leitungsrohr mit Kanal und Washcoat ist unten abgebildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82508897-85c6-4058-836d-ba8e9868b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"channel_washcoat.png\", width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990300a6-e820-4883-8b4d-1e8bb7c90951",
   "metadata": {},
   "source": [
    "Ziel ist es, einen möglichst geringen Ausfluss der Schadstoffs am Ausflussrand bei gleichzeitig möglichst großem Durchsatz zu erreichen. Es soll also möglichst viel des kontaminierten Stoffes in das Rohr geleitet werden (vom Einfluss- zum Ausflussrand) und dabei möglichst viel des Schadstoffes entfernt werden (durch die Reaktion mit dem Filtermaterial im Washcoat). Allerdings sind die Kosten zur Konstruktion eines besonders effizienten Filters (das heißt mit besonders starker Reaktion, also einem großen Wert der Damköhler-Zahl $\\mathrm{Da}$) hoch. Dies gilt es beim Design des Filters zu berücksichtigen. Zusammenfassend soll das folgende Optimierungsproblem mit der Zielfunktion $\\mathcal{J}\\colon\\mathcal{P}\\to\\mathbb{R}$ gelöst werden:\n",
    "\n",
    "$$\n",
    "    \\min_{\\mu\\in\\mathcal{P}} \\mathcal{J}(\\mu),\\qquad\\qquad\\mathcal{J}(\\mu):=\\int\\limits_{0}^{T}\\underbrace{\\left(\\frac{1}{|\\Gamma_\\mathrm{out}|}\\int\\limits_{\\Gamma_\\mathrm{out}}u(t;\\mu)\\,\\mathrm{d}s\\right)}_{\\text{Schadstoff am Ausfluss zum Zeitpunkt }t}\\,\\mathrm{d}t + \\underbrace{\\frac{\\mathrm{Da}^2}{500}}_{Produktionskosten} - \\underbrace{\\frac{(\\mathrm{Pe} - 9)^2}{10}}_{Durchsatz}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0b3b3-0cb3-447e-8630-dba04b443d95",
   "metadata": {},
   "source": [
    "# Adaptive Modellhierarchien\n",
    "\n",
    "Um möglichst effiziente Filter zu bauen, sind Simulationen des Verhaltens verschiedener Filter mit verschiedenen Wahlen der Parameter $\\mu=(\\mathrm{Da},\\mathrm{Pe})\\in\\mathcal{P}$ notwendig. Die gegebene partielle Differentialgleichung wird hierzu zunächst mit der Methode der Finiten Elemente diskretisiert. Dadurch erhalten wir das sogenannte Full order model (FOM). Dieses liefert sehr genaue Lösungen, allerdings ist die Berechnung der Lösung für einen einzelnen bereits recht aufwendig. Mithilfe geeigneter Trainingsdaten können wir jedoch ein reduziertes Modell, das RB-ROM, konstruieren, das eine näherungsweise Lösung berechnet und deutlich schneller als das FOM ist. Dieses RB-ROM können wir zudem durch Ansätze aus dem maschinellen Lernen ergänzen, was uns insgesamt das ML-ROM liefert.\n",
    "\n",
    "Für das RB-ROM und das ML-ROM existiert ein Fehlerschätzer $\\eta_\\mu$, den wir nutzen können, um eine obere Schranke für den Approximationsfehler gegenüber der Lösung des FOM zu bestimmen. Wir möchten bei unseren Simulationen nur solche Lösungen akzeptieren, deren Fehler kleiner als eine vorgegebene Toleranz beziehungsweise Rechengenauigkeit sind. Das RB-ROM und das ML-ROM können automatisch mit zusätzlichen Daten des FOM trainiert werden, um die entsprechende Rechengenauigkeit zu erreichen.\n",
    "\n",
    "Die verschiedenen Modelle können in einer adaptiven Modellhierarchie kombiniert werden, um ihre individuellen Vorteile hinsichtlich Rechenzeit und Genauigkeit bestmöglichst auszunutzen. Insgesamt ergibt sich ein effizientes Zusammenspiel der verschiedenen Verfahren, die sich insbesondere gegenseitig zusätzliche Trainingsdaten liefern und sich daher gegenseitig verbessern. Der Einsatz des Fehlerschätzers ermöglicht zudem, eine Garantie für die Rechengenauigkeit abzugeben. Der Fehler der berechneten (approximativen) Lösung wird also immer unterhalb der vorgegebenen Toleranz liegen, notfalls wird auf das FOM zurückgegriffen, um die gewünschte Genauigkeit sicherzustellen.\n",
    "\n",
    "<style>.myst, .myst p {font-size: 20pt;}</style>\n",
    "\n",
    "## Überblick über die verschiedenen Modelle\n",
    "\n",
    "| Modell | Bezeichnung für die Lösung zum Parameter $\\mu$ | Genauigkeit | Rechenaufwand | Sonstiges |\n",
    "|--------|-------------|---------------|-----------|-----------|\n",
    "| FOM    | $u(\\mu)$ | Hinreichend genau für alle Parameter (Referenzlösung) | Sehr aufwendig | - |\n",
    "| RB-ROM | $u^N(\\mu)$ | Etwas ungenauer als das FOM | Deutlich schneller als das FOM | Effiziente Fehlerschätzung möglich |\n",
    "| ML-ROM | $\\tilde{u}^N(\\mu)$ | Ungenauer als das RB-ROM | Schneller als das RB-ROM | Fehlerschätzung vom RB-ROM kann wiederverwendet werden |\n",
    "\n",
    "## Visualisierung der Modellhierarchie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ce8dc-5e9c-418c-8c27-b9f717327cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"model_hierarchy.png\", width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769e61c-4a0e-4489-a864-0b93d4e81b10",
   "metadata": {},
   "source": [
    "## Anwendungsszenarien in der interaktiven Simulation\n",
    "\n",
    "In der Simulation unten werden verschiedene Anwendungsszenarien betrachtet:\n",
    "\n",
    "### Manuelle Parameterwahl\n",
    "\n",
    "Durch Anklicken des entsprechenden Punkts im Parameterraum, kann der entsprechende Parameter manuelle gewählt werden und die adaptive Modellhierarchie wird automatisch für den gewählten Parameter aufgerufen und die Lösung berechnet. Des Weiteren wird der zugehörige Zielfunktionswert für die Kostenfunktion in einem Graphen aufgetragen.\n",
    "\n",
    "### Parameteroptimierung\n",
    "\n",
    "Wie oben beschrieben, möchten wir den Parameter bestimmen, der den besten Kosten-Nutzen-Wert liefert, das heißt das beste Verhältnis zwischen Filterleistung, Durchsatz und Herstellungskosten darstellt. Hierzu kann ein Optimierungsalgorithmus genutzt werden, der auf mehrfacher Auswertung der Zielfunktion für verschiedene Parameterwerte basiert. Die Auswertung der Zielfunktion für einen gegebenen Parameter benötigt die Lösung der Differentialgleichung, welche mittels der adaptiven Modellhierarchie näherungsweise bestimmt wird. Die Modellhierarchie kann also eingebettet in einen Optimierungsalgorithmus genutzt werden.\n",
    "\n",
    "### Abschätzung der Auswirkungen von Materialunsicherheiten\n",
    "\n",
    "Typischerweise ist es sehr schwierig, Filtermaterialien mit exakt den vorgegebenen Eigenschaften herzustellen. Selbst wenn ein optimaler Parameter gefunden ist, wird der tatsächlich produzierte Filter kleinere Abweichungen vom gewünschten Verhalten aufweisen. Um diese Abweichungen zu untersuchen, kann eine sogenannte Monte Carlo Simulation genutzt werden, bei der der durchschnittliche Zielfunktionswert für eine gegebene Verteilung der auftretenden Parameter mit Hilfe von einer großen Zahl an Simulationen geschätzt wird. Hierbei wird der durchschnittliche Zielfunktionswert einfach als Mittel über die Ergebnisse sämtlicher Simulationen angenähert. Werden viele Simulationen durchgeführt, so liefert dieses Verfahren eine gute Approximation des tatsächlich gesuchten Erwartungswertes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7e44a-cc17-4ea1-9e0f-8908cf80b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_model_hierarchy(three_stage_hierarchy, parameter_space, model_names,\n",
    "                         output_function=objective_function, objective_function=objective_function, initial_parameter=mu_init, optimal_parameter=mu_opt, optimization_bg_image=\"fig_optimization_background_new.png\", optimization_bg_image_limits=(0.0278514264616242, 0.000111348743739251), show_solution=True, visualizer=fom.visualizer, random_sampling_function=random_sampling_function, density_function_monte_carlo=density_function_monte_carlo, solution_plot_extent=(0, 2.5, 0, 1), language='de',\n",
    "                         fig_width=17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
